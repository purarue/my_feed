#!/usr/bin/env zsh
# if FEED_REINDEX=1 ./index , this removes all the data from the remote database and re-builds it
# the remote database and re-builds it

with_secrets_script="${HOME}/.local/scripts/generic/with-secrets"
if [[ -f "$with_secrets_script" ]]; then
	echo 'Sourcing secrets file...' >&2
	source "$with_secrets_script" || true
else
	echo 'Missing with-secrets script' >&2
	exit 1
fi

set -e

declare -a CURL_AUTH_OPTS=()
declare SSH_TARGET
# setup Host in your ~/.ssh/config file
SSH_TARGET="${SSH_TARGET:-vultr}"

[[ -n "$FEED_REINDEX" ]] && printf 'Re'
echo "Indexing..."

wait-for-internet -q --timeout 30 || exit 0

cd "$(realpath "$(dirname "${BASH_SOURCE[0]}")")" || exit $?

[[ -n "$MY_FEED_SECRET" ]] && CURL_AUTH_OPTS=("-H" "token:$MY_FEED_SECRET")

# temporary dir for new data
TMPDIR="$(mktemp -d)"
# https://github.com/seanbreckenridge/core/blob/main/shellscripts/epoch
JSON="${TMPDIR}/$(epoch).json" || exit $?

# warm tz cache incase its expired, use flock incase something else is already running doctor
flock ~/.local/tz-lock hpi doctor -S my.time.tz.via_location

# run an index
INDEX_ARGS=()
# if we have a list of blurred images, pass it to the indexer
BLURRED_IMAGES="${HPIDATA}/feed_blurred_images.txt"
if [[ -f "$BLURRED_IMAGES" ]]; then
	# if we have a list of blurred images, pass it to the indexer
	INDEX_ARGS+=("-B" "$BLURRED_IMAGES")
fi
if [[ -z "$FEED_REINDEX" ]]; then
	# if were not re-indexing, fetch the list of IDs we've already indexed from the server
	# and pass it to the indexer, so it can skip uploading those
	curl "${CURL_AUTH_OPTS[@]}" -sL 'https://sean.fish/feed_api/data/ids' >"${TMPDIR}/ids.json" || exit $?
	INDEX_ARGS+=("-E" "${TMPDIR}/ids.json")
	# stuff to ignore here which takes a long time and/or doesnt commonly change
	# can be pushed just when doing a re-index
	export MY_FEED_EXCLUDE_SOURCES='mal.deleted,games.steam,games.grouvee,games.game_center,facebook_spotify_listens,games.osrs'
else
	# running a re-index, so update the approved IDs
	#
	# update approved IDs for computing deleted anime entry data
	# https://github.com/seanbreckenridge/malexport/#recover_deleted
	python3 -m malexport recover-deleted approved-update
	# set prefix for indexer
	export RUNELITE_PHOTOS_PREFIX='https://sean.fish/p/'
	echo 'Syncing OSRS images...' >&2
	REMSYNC_PUBLIC=1 "${REPOS}/vps/remsync" "$(python3 -m my.utils.backup_to runelite_screenshots)" >/dev/null || exit $?
fi

# write count to file
INDEX_ARGS+=("-C" "${TMPDIR}/count.txt")
flock ~/.local/feed-lock my_feed index "${INDEX_ARGS[@]}" "$JSON" || exit $?

COUNT="$(cat "${TMPDIR}/count.txt")"

# if ids.json/count.txt file exists, delete it
[[ -f "${TMPDIR}/ids.json" ]] && command rm -fv "${TMPDIR}/ids.json"
[[ -f "${TMPDIR}/count.txt" ]] && command rm -fv "${TMPDIR}/count.txt"

# if the json file is empty, don't bother uploading
if [[ "$COUNT" -eq 0 ]]; then
	echo 'No new data, exiting' >&2
	# delete temp file
	command rm -f "${JSON}"
	exit 0
fi

# https://github.com/seanbreckenridge/core
# compress json files in the data dir
fd -d 1 --full-path '.*fixes.json' "$HPIDATA" -X json-compress

# https://github.com/seanbreckenridge/wait-for-internet
# wait for internet, if we don't have it, don't bother uploading
wait-for-internet -q --timeout "${WFI_TIMEOUT:-10}" || exit 0

# delete remote json files if we want to reset
[[ -n "$FEED_REINDEX" ]] && ssh "${SSH_TARGET}" 'rm -vf ~/code/my_feed/backend/data/*.json'

# copy up to the server
flock ~/.local/feed-sync-lock scp "${JSON}" "${SSH_TARGET}":~/code/my_feed/backend/data

# delete temp file
command rm -f "${JSON}"

if [[ -n "$FEED_REINDEX" ]]; then
	echo 'Rebuilding database...'
	printf '%s\n' "$(curl "${CURL_AUTH_OPTS[@]}" -sL 'https://sean.fish/feed_api/recheck')"
else
	# otherwise this is just new data, just ping the server to check for new files
	echo 'Running update...'
	printf '%s\n' "$(curl "${CURL_AUTH_OPTS[@]}" -sL 'https://sean.fish/feed_api/check')"
fi
# hmm.. for some reason shelling out to pipenv/python causes CPU to spike and it never seems to go down
# unsure if it has to do with database connections or something else
# hack for now, just restart the backend, will migrate to a fully golang backend soon
ssh "$SSH_TARGET" '~/vps/super --ctl restart feed-backend'
